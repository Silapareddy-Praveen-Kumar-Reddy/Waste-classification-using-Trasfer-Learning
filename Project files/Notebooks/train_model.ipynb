{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a8d620e-1a6a-4d29-9fa5-7a4e561a7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "RAW_DATA_DIR = '../data/raw'\n",
    "OUTPUT_DIR = '../data/output_dataset'\n",
    "MODEL_SAVE_PATH = '../w_flask/vgg16.h5'\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d22b0b9e-c8a5-41a2-88a0-665fdb4ef2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    checkpoint_path = f\"data/output_dataset/{split}/.ipynb_checkpoints\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        shutil.rmtree(checkpoint_path)\n",
    "        print(f\"✅ Removed: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9729274-c5f8-462d-82b1-a4eee34e5a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 259 images belonging to 3 classes.\n",
      "{'Biodegradable Images': 0, 'Recyclable Images': 1, 'Trash Images': 2}\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "train_dir = '../data/output_dataset/train'\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13978fcc-638b-40ab-9c53-2243bb803d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biodegradable Images: 130 images\n",
      "Recyclable Images: 131 images\n",
      "Trash Images: 130 images\n"
     ]
    }
   ],
   "source": [
    "# Preview image counts\n",
    "for cls in os.listdir(RAW_DATA_DIR):\n",
    "    files = os.listdir(os.path.join(RAW_DATA_DIR, cls))\n",
    "    print(f\"{cls}: {len(files)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b841fad0-045b-4aef-b7c7-cbb787c2c46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split into train, val, and test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define valid image extensions\n",
    "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "\n",
    "# Get list of class directories (assuming they are subdirectories in RAW_DATA_DIR)\n",
    "classes = [d for d in os.listdir(RAW_DATA_DIR) if os.path.isdir(os.path.join(RAW_DATA_DIR, d))]\n",
    "\n",
    "for cls in classes:\n",
    "    img_dir = os.path.join(RAW_DATA_DIR, cls)\n",
    "    all_files = os.listdir(img_dir)\n",
    "    # Only keep image files\n",
    "    images = [img for img in all_files if img.lower().endswith(valid_exts)]\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(f\"Skipping {cls}, no valid images.\")\n",
    "        continue\n",
    "    \n",
    "    # Split data: 60% train, 20% validation, 20% test\n",
    "    train_val, test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    for img in train:\n",
    "        shutil.copy(os.path.join(img_dir, img), os.path.join(OUTPUT_DIR, 'train', cls, img))\n",
    "    \n",
    "    for img in val:\n",
    "        shutil.copy(os.path.join(img_dir, img), os.path.join(OUTPUT_DIR, 'val', cls, img))\n",
    "    \n",
    "    for img in test:\n",
    "        shutil.copy(os.path.join(img_dir, img), os.path.join(OUTPUT_DIR, 'test', cls, img))\n",
    "\n",
    "print(\"✅ Dataset split into train, val, and test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb90cf5-9738-47ca-ba65-4ac59effb3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1095164b-704c-48ef-ab2a-94e56efc1804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 259 images belonging to 3 classes.\n",
      "Found 78 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 65s 7s/step - loss: 4.3296 - accuracy: 0.6062 - val_loss: 3.1845 - val_accuracy: 0.6282\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 71s 8s/step - loss: 1.3110 - accuracy: 0.8571 - val_loss: 1.8116 - val_accuracy: 0.8077\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 80s 9s/step - loss: 0.6698 - accuracy: 0.8919 - val_loss: 1.4385 - val_accuracy: 0.8205\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 67s 8s/step - loss: 0.4483 - accuracy: 0.9189 - val_loss: 1.2247 - val_accuracy: 0.8077\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.2343 - accuracy: 0.9305 - val_loss: 1.1367 - val_accuracy: 0.8718\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 64s 7s/step - loss: 0.0750 - accuracy: 0.9614 - val_loss: 1.0359 - val_accuracy: 0.8718\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 63s 7s/step - loss: 0.0493 - accuracy: 0.9768 - val_loss: 0.9869 - val_accuracy: 0.8718\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 60s 7s/step - loss: 0.1017 - accuracy: 0.9768 - val_loss: 0.8688 - val_accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.0445 - accuracy: 0.9807 - val_loss: 0.8217 - val_accuracy: 0.8974\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 44s 5s/step - loss: 0.0270 - accuracy: 0.9884 - val_loss: 0.8452 - val_accuracy: 0.8846\n",
      "✅ Model trained and saved!\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(OUTPUT_DIR, 'train')\n",
    "val_dir = os.path.join(OUTPUT_DIR, 'val')\n",
    "\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                               rotation_range=20, zoom_range=0.2, horizontal_flip=True).flow_from_directory(\n",
    "    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n",
    "    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")\n",
    "\n",
    "base = VGG16(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "x = Flatten()(base.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "out = Dense(len(train_gen.class_indices), activation='softmax')(x)\n",
    "model = Model(base.input, out)\n",
    "\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_gen, epochs=EPOCHS, validation_data=val_gen)\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(\"✅ Model trained and saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
