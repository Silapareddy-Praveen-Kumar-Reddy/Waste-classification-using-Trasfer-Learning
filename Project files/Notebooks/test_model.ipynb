{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80f67ca-3ce2-42bd-b8b2-4df7b3d92964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 259 images belonging to 3 classes.\n",
      "Found 78 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 8.3466 - accuracy: 0.2394 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.29487, saving model to vgg16.h5\n",
      "9/9 [==============================] - 39s 4s/step - loss: 8.3466 - accuracy: 0.2394 - val_loss: 5.3370 - val_accuracy: 0.2949\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 7.8029 - accuracy: 0.2973 \n",
      "Epoch 2: val_accuracy did not improve from 0.29487\n",
      "9/9 [==============================] - 39s 4s/step - loss: 7.8029 - accuracy: 0.2973 - val_loss: 5.0072 - val_accuracy: 0.2821\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 7.3115 - accuracy: 0.2780 \n",
      "Epoch 3: val_accuracy did not improve from 0.29487\n",
      "9/9 [==============================] - 39s 5s/step - loss: 7.3115 - accuracy: 0.2780 - val_loss: 4.6470 - val_accuracy: 0.2949\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 6.6055 - accuracy: 0.3166 \n",
      "Epoch 4: val_accuracy did not improve from 0.29487\n",
      "9/9 [==============================] - 42s 5s/step - loss: 6.6055 - accuracy: 0.3166 - val_loss: 4.2899 - val_accuracy: 0.2949\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 6.6600 - accuracy: 0.3012 \n",
      "Epoch 5: val_accuracy improved from 0.29487 to 0.32051, saving model to vgg16.h5\n",
      "9/9 [==============================] - 43s 5s/step - loss: 6.6600 - accuracy: 0.3012 - val_loss: 3.9575 - val_accuracy: 0.3205\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 6.4332 - accuracy: 0.3089 \n",
      "Epoch 6: val_accuracy improved from 0.32051 to 0.34615, saving model to vgg16.h5\n",
      "9/9 [==============================] - 41s 5s/step - loss: 6.4332 - accuracy: 0.3089 - val_loss: 3.6592 - val_accuracy: 0.3462\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 6.6869 - accuracy: 0.3012 \n",
      "Epoch 7: val_accuracy did not improve from 0.34615\n",
      "9/9 [==============================] - 45s 5s/step - loss: 6.6869 - accuracy: 0.3012 - val_loss: 3.3946 - val_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 6.1640 - accuracy: 0.2973    \n",
      "Epoch 8: val_accuracy did not improve from 0.34615\n",
      "9/9 [==============================] - 43s 5s/step - loss: 6.1640 - accuracy: 0.2973 - val_loss: 3.1814 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 6.1721 - accuracy: 0.3166 \n",
      "Epoch 9: val_accuracy improved from 0.34615 to 0.35897, saving model to vgg16.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 6.1721 - accuracy: 0.3166 - val_loss: 2.9908 - val_accuracy: 0.3590\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 5.7734 - accuracy: 0.3166 \n",
      "Epoch 10: val_accuracy improved from 0.35897 to 0.37179, saving model to vgg16.h5\n",
      "9/9 [==============================] - 42s 5s/step - loss: 5.7734 - accuracy: 0.3166 - val_loss: 2.8096 - val_accuracy: 0.3718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2036698a9d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "# Config\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 3\n",
    "EPOCHS = 10\n",
    "\n",
    "train_dir = '../data/output_dataset/train'\n",
    "val_dir = '../data/output_dataset/val'\n",
    "\n",
    "# Data generators\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_data = val_gen.flow_from_directory(val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "\n",
    "# Base model\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "os.makedirs('models', exist_ok=True)\n",
    "checkpoint = ModelCheckpoint('vgg16.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "model.fit(train_data, validation_data=val_data, epochs=EPOCHS, callbacks=[checkpoint, earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518957c5-094c-4350-8556-455f8c5bf2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78 images belonging to 3 classes.\n",
      "78/78 [==============================] - 13s 171ms/step - loss: 2.8778 - accuracy: 0.3333\n",
      "Test Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "test_dir = '../data/output_dataset/test'\n",
    "test_data = val_gen.flow_from_directory(test_dir, target_size=IMG_SIZE, batch_size=1, class_mode='categorical', shuffle=False)\n",
    "\n",
    "loss, acc = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
